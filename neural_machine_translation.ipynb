{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanikohli/Documents/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import pickle\n",
    "import data_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_sentences(file_path):\n",
    "\tsentences = []\n",
    "\n",
    "\twith open(file_path, 'r') as reader:\n",
    "\t\tfor s in reader:\n",
    "\t\t\tsentences.append(s.strip())\n",
    "\n",
    "\treturn sentences\n",
    "\n",
    "def iteritems(dic):\n",
    "    return iter([(key, dic[key]) for key in dic])\n",
    "\n",
    "def create_dataset(en_sentences, de_sentences):\n",
    "\n",
    "\ten_vocab_dict = Counter(word.strip(',.\" ;:)(][?!') for sentence in en_sentences for word in sentence.split())\n",
    "\tde_vocab_dict = Counter(word.strip(',.\" ;:)(][?!') for sentence in de_sentences for word in sentence.split())\n",
    "\n",
    "\ten_vocab = list(map(lambda x: x[0], sorted(en_vocab_dict.items(), key = lambda x: -x[1])))\n",
    "\tde_vocab = list(map(lambda x: x[0], sorted(de_vocab_dict.items(), key = lambda x: -x[1])))\n",
    "\n",
    "\ten_vocab = en_vocab[:20000]\n",
    "\tde_vocab = de_vocab[:30000]\n",
    "\n",
    "\tstart_idx = 2\n",
    "\ten_word2idx = dict([(word, idx+start_idx) for idx, word in enumerate(en_vocab)])\n",
    "\ten_word2idx['<ukn>'] = 0\n",
    "\ten_word2idx['<pad>'] = 1\n",
    "\n",
    "\ten_idx2word = dict([(idx, word) for word, idx in iteritems(en_word2idx)])\n",
    "\n",
    "\n",
    "\tstart_idx = 4\n",
    "\tde_word2idx = dict([(word, idx+start_idx) for idx, word in enumerate(de_vocab)])\n",
    "\tde_word2idx['<ukn>'] = 0\n",
    "\tde_word2idx['<go>']  = 1\n",
    "\tde_word2idx['<eos>'] = 2\n",
    "\tde_word2idx['<pad>'] = 3\n",
    "\n",
    "\tde_idx2word = dict([(idx, word) for word, idx in iteritems(de_word2idx)])\n",
    "\n",
    "\tx = [[en_word2idx.get(word.strip(',.\" ;:)(][?!'), 0) for word in sentence.split()] for sentence in en_sentences]\n",
    "\ty = [[de_word2idx.get(word.strip(',.\" ;:)(][?!'), 0) for word in sentence.split()] for sentence in de_sentences]\n",
    "\n",
    "\tX = []\n",
    "\tY = []\n",
    "\tfor i in range(len(x)):\n",
    "\t\tn1 = len(x[i])\n",
    "\t\tn2 = len(y[i])\n",
    "\t\tn = n1 if n1 < n2 else n2 \n",
    "\t\tif abs(n1 - n2) <= 0.3 * n:\n",
    "\t\t\tif n1 <= 15 and n2 <= 15:\n",
    "\t\t\t\tX.append(x[i])\n",
    "\t\t\t\tY.append(y[i])\n",
    "\n",
    "\treturn X, Y, en_word2idx, en_idx2word, en_vocab, de_word2idx, de_idx2word, de_vocab\n",
    "\n",
    "def save_dataset(file_path, obj):\n",
    "\twith open(file_path, 'wb') as f:\n",
    "\t\tpickle.dump(obj, f, -1)\n",
    "\n",
    "def main():\n",
    "    en_sentences = read_sentences('bible.en')\n",
    "    de_sentences = read_sentences('bible.san')\n",
    "\n",
    "    save_dataset('./bible.pkl', create_dataset(en_sentences, de_sentences))\n",
    "    save_dataset('./bible2.pkl', create_dataset(de_sentences, en_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "def read_dataset(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f,encoding=\"utf_8\")\n",
    "\n",
    "X, Y, en_word2idx, en_idx2word, en_vocab, de_word2idx, de_idx2word, de_vocab = read_dataset('bible2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "\n",
    "# data padding\n",
    "def data_padding(x, y, length = 15):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] + (length - len(x[i])) * [en_word2idx['<pad>']]\n",
    "        y[i] = [de_word2idx['<go>']] + y[i] + [de_word2idx['<eos>']] + (length-len(y[i])) * [de_word2idx['<pad>']]\n",
    "\n",
    "data_padding(X, Y)\n",
    "\n",
    "# data splitting\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "input_seq_len = 15\n",
    "output_seq_len = 17\n",
    "en_vocab_size = len(en_vocab) + 2 # + <pad>, <ukn>\n",
    "de_vocab_size = len(de_vocab) + 4 # + <pad>, <ukn>, <eos>, <go>\n",
    "\n",
    "# placeholders\n",
    "encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "targets = [decoder_inputs[i+1] for i in range(output_seq_len-1)]\n",
    "# add one more target\n",
    "targets.append(tf.placeholder(dtype = tf.int32, shape = [None], name = 'last_target'))\n",
    "target_weights = [tf.placeholder(dtype = tf.float32, shape = [None], name = 'target_w{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "# output projection\n",
    "size = 512\n",
    "w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "w = tf.transpose(w_t)\n",
    "output_projection = (w, b)\n",
    "\n",
    "outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                            encoder_inputs,\n",
    "                                            decoder_inputs,\n",
    "                                            tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                            num_encoder_symbols = en_vocab_size,\n",
    "                                            num_decoder_symbols = de_vocab_size,\n",
    "                                            embedding_size = 100,\n",
    "                                            feed_previous = False,\n",
    "                                            output_projection = output_projection,\n",
    "                                            dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shivanikohli/Documents/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:1346: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define our loss function\n",
    "\n",
    "# sampled softmax loss - returns: A batch_size 1-D tensor of per-example sampled softmax losses\n",
    "def sampled_loss(labels, logits):\n",
    "    return tf.nn.sampled_softmax_loss(\n",
    "                        weights = w_t,\n",
    "                        biases = b,\n",
    "                        labels = tf.reshape(labels, [-1, 1]),\n",
    "                        inputs = logits,\n",
    "                        num_sampled = 512,\n",
    "                        num_classes = de_vocab_size)\n",
    "\n",
    "# Weighted cross-entropy loss for a sequence of logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss(outputs, targets, target_weights, softmax_loss_function = sampled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some helper functions\n",
    "\n",
    "# simple softmax function\n",
    "def softmax(x):\n",
    "    n = np.max(x)\n",
    "    e_x = np.exp(x - n)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# feed data into placeholders\n",
    "def feed_dict(x, y, batch_size = 64):\n",
    "    feed = {}\n",
    "    \n",
    "    idxes = np.random.choice(len(x), size = batch_size, replace = False)\n",
    "    \n",
    "    for i in range(input_seq_len):\n",
    "        feed[encoder_inputs[i].name] = np.array([x[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    for i in range(output_seq_len):\n",
    "        feed[decoder_inputs[i].name] = np.array([y[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    feed[targets[len(targets)-1].name] = np.full(shape = [batch_size], fill_value = de_word2idx['<pad>'], dtype = np.int32)\n",
    "    \n",
    "    for i in range(output_seq_len-1):\n",
    "        batch_weights = np.ones(batch_size, dtype = np.float32)\n",
    "        target = feed[decoder_inputs[i+1].name]\n",
    "        for j in range(batch_size):\n",
    "            if target[j] == de_word2idx['<pad>']:\n",
    "                batch_weights[j] = 0.0\n",
    "        feed[target_weights[i].name] = batch_weights\n",
    "        \n",
    "    feed[target_weights[output_seq_len-1].name] = np.zeros(batch_size, dtype = np.float32)\n",
    "    \n",
    "    return feed\n",
    "\n",
    "# decode output sequence\n",
    "def decode_output(output_seq):\n",
    "    words = []\n",
    "    for i in range(output_seq_len):\n",
    "        smax = softmax(output_seq[i])\n",
    "        idx = np.argmax(smax)\n",
    "        words.append(de_idx2word[idx])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops and hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "steps = 1000\n",
    "\n",
    "# ops for projecting outputs\n",
    "outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "# training op\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# init op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# forward step\n",
    "def forward_step(sess, feed):\n",
    "    output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "    return output_sequences\n",
    "\n",
    "# training step\n",
    "def backward_step(sess, feed):\n",
    "    sess.run(optimizer, feed_dict = feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess=tf.Session()    \n",
    "# #First let's load meta graph and restore weights\n",
    "# saver = tf.train.import_meta_graph('checkpointsSan/-199.meta')\n",
    "# saver.restore(sess,tf.train.latest_checkpoint('checkpointsSan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "step: 0, loss: 7.971765041351318\n",
      "step: 4, loss: 7.9435601234436035\n",
      "step: 9, loss: 7.998272895812988\n",
      "step: 14, loss: 7.989370346069336\n",
      "step: 19, loss: 7.968928813934326\n",
      "Checkpoint is saved\n",
      "step: 24, loss: 7.974762916564941\n",
      "step: 29, loss: 7.903650760650635\n",
      "step: 34, loss: 7.85491943359375\n",
      "step: 39, loss: 7.802876949310303\n",
      "Checkpoint is saved\n",
      "step: 44, loss: 7.416131019592285\n",
      "step: 49, loss: 6.534648895263672\n",
      "step: 54, loss: 6.0618577003479\n",
      "step: 59, loss: 5.861288070678711\n",
      "Checkpoint is saved\n",
      "step: 64, loss: 5.809093475341797\n",
      "step: 69, loss: 5.178417205810547\n",
      "step: 74, loss: 5.660608291625977\n",
      "step: 79, loss: 4.575555324554443\n",
      "Checkpoint is saved\n",
      "step: 84, loss: 6.619039058685303\n",
      "step: 89, loss: 5.202486991882324\n",
      "step: 94, loss: 4.522871017456055\n",
      "step: 99, loss: 4.375219345092773\n",
      "Checkpoint is saved\n",
      "step: 104, loss: 4.042259216308594\n",
      "step: 109, loss: 4.2842864990234375\n",
      "step: 114, loss: 10.245833396911621\n",
      "step: 119, loss: 4.766635894775391\n",
      "Checkpoint is saved\n",
      "step: 124, loss: 4.279655456542969\n",
      "step: 129, loss: 3.4309496879577637\n",
      "step: 134, loss: 3.5621156692504883\n",
      "step: 139, loss: 3.157196044921875\n",
      "Checkpoint is saved\n",
      "step: 144, loss: 2.6231343746185303\n",
      "step: 149, loss: 2.8525891304016113\n",
      "step: 154, loss: 2.6881232261657715\n",
      "step: 159, loss: 2.4895169734954834\n",
      "Checkpoint is saved\n",
      "step: 164, loss: 1.7581285238265991\n",
      "step: 169, loss: 2.2701072692871094\n",
      "step: 174, loss: 1.484368085861206\n",
      "step: 179, loss: 1.5915757417678833\n",
      "Checkpoint is saved\n",
      "step: 184, loss: 1.0561490058898926\n",
      "step: 189, loss: 1.2776826620101929\n",
      "step: 194, loss: 2.7549118995666504\n",
      "step: 199, loss: 0.8423110246658325\n",
      "Checkpoint is saved\n",
      "step: 204, loss: 0.39476004242897034\n",
      "step: 209, loss: 0.2636072337627411\n",
      "step: 214, loss: 0.23041172325611115\n",
      "step: 219, loss: 1.1298160552978516\n",
      "Checkpoint is saved\n",
      "step: 224, loss: 0.7206742763519287\n",
      "step: 229, loss: 0.07882022857666016\n",
      "step: 234, loss: 0.07455281913280487\n",
      "step: 239, loss: 0.032466817647218704\n",
      "Checkpoint is saved\n",
      "step: 244, loss: 0.043197885155677795\n",
      "step: 249, loss: 0.5757489204406738\n",
      "step: 254, loss: 3.030734062194824\n",
      "step: 259, loss: 0.07621507346630096\n",
      "Checkpoint is saved\n",
      "step: 264, loss: 0.03959920257329941\n",
      "step: 269, loss: 0.01434384100139141\n",
      "step: 274, loss: 0.01981312967836857\n",
      "step: 279, loss: 0.037286099046468735\n",
      "Checkpoint is saved\n",
      "step: 284, loss: 0.013829117640852928\n",
      "step: 289, loss: 0.008852229453623295\n",
      "step: 294, loss: 0.002884862944483757\n",
      "step: 299, loss: 0.010787379927933216\n",
      "Checkpoint is saved\n",
      "step: 304, loss: 0.2587909698486328\n",
      "step: 309, loss: 2.07958984375\n",
      "step: 314, loss: 0.021981490775942802\n",
      "step: 319, loss: 0.0035735582932829857\n",
      "Checkpoint is saved\n",
      "step: 324, loss: 0.008066208101809025\n",
      "step: 329, loss: 0.0032089068554341793\n",
      "step: 334, loss: 0.009165722876787186\n",
      "step: 339, loss: 0.0010150575544685125\n",
      "Checkpoint is saved\n",
      "step: 344, loss: 0.01563199609518051\n",
      "step: 349, loss: 1.118296504020691\n",
      "step: 354, loss: 0.12121934443712234\n",
      "step: 359, loss: 0.003582339035347104\n",
      "Checkpoint is saved\n",
      "step: 364, loss: 0.000962779566179961\n",
      "step: 369, loss: 0.0015539622399955988\n",
      "step: 374, loss: 0.022245660424232483\n",
      "step: 379, loss: 0.0070583452470600605\n",
      "Checkpoint is saved\n",
      "step: 384, loss: 0.00045501001295633614\n",
      "step: 389, loss: 0.00035588047467172146\n",
      "step: 394, loss: 0.0008293455466628075\n",
      "step: 399, loss: 0.0025169001892209053\n",
      "Checkpoint is saved\n",
      "step: 404, loss: 0.00014260064926929772\n",
      "step: 409, loss: 2.048430919647217\n",
      "step: 414, loss: 0.031871646642684937\n",
      "step: 419, loss: 0.0068620252422988415\n",
      "Checkpoint is saved\n",
      "step: 424, loss: 0.02674846164882183\n",
      "step: 429, loss: 0.0004597375518642366\n",
      "step: 434, loss: 0.00028388373902998865\n",
      "step: 439, loss: 0.0006971062393859029\n",
      "Checkpoint is saved\n",
      "step: 444, loss: 0.0008397888159379363\n",
      "step: 449, loss: 0.012417520396411419\n",
      "step: 454, loss: 0.00024375856446567923\n",
      "step: 459, loss: 0.01939927600324154\n",
      "Checkpoint is saved\n",
      "step: 464, loss: 2.5943233966827393\n",
      "step: 469, loss: 0.009820929728448391\n",
      "step: 474, loss: 0.00525943748652935\n",
      "step: 479, loss: 0.0004377091827336699\n",
      "Checkpoint is saved\n",
      "step: 484, loss: 0.0003730787429958582\n",
      "step: 489, loss: 0.0029108314774930477\n",
      "step: 494, loss: 0.0003429246717132628\n",
      "step: 499, loss: 0.0019989453721791506\n",
      "Checkpoint is saved\n",
      "step: 504, loss: 0.0001867800165200606\n",
      "step: 509, loss: 0.0001585744903422892\n",
      "step: 514, loss: 0.3176876902580261\n",
      "step: 519, loss: 0.05719918757677078\n",
      "Checkpoint is saved\n",
      "step: 524, loss: 0.10208532214164734\n",
      "step: 529, loss: 0.009857391938567162\n",
      "step: 534, loss: 0.09278494119644165\n",
      "step: 539, loss: 0.009371735155582428\n",
      "Checkpoint is saved\n",
      "step: 544, loss: 0.00010966342233587056\n",
      "step: 549, loss: 0.0004007311654277146\n",
      "step: 554, loss: 7.231994095491245e-05\n",
      "step: 559, loss: 7.857051241444424e-05\n",
      "Checkpoint is saved\n",
      "step: 564, loss: 4.848566823056899e-05\n",
      "step: 569, loss: 0.0007996332133188844\n",
      "step: 574, loss: 0.4981941878795624\n",
      "step: 579, loss: 0.004322317894548178\n",
      "Checkpoint is saved\n",
      "step: 584, loss: 0.007070089224725962\n",
      "step: 589, loss: 9.873101953417063e-05\n",
      "step: 594, loss: 0.030906742438673973\n",
      "step: 599, loss: 0.02403470315039158\n",
      "Checkpoint is saved\n",
      "step: 604, loss: 0.004334408789873123\n",
      "step: 609, loss: 0.3267153799533844\n",
      "step: 614, loss: 0.25094178318977356\n",
      "step: 619, loss: 0.28198307752609253\n",
      "Checkpoint is saved\n",
      "step: 624, loss: 0.010421749204397202\n",
      "step: 629, loss: 0.00022413844999391586\n",
      "step: 634, loss: 8.343229274032637e-05\n",
      "step: 639, loss: 4.094672476639971e-05\n",
      "Checkpoint is saved\n",
      "step: 644, loss: 0.0001487444096710533\n",
      "step: 649, loss: 0.0009530684328638017\n",
      "step: 654, loss: 7.02607721905224e-05\n",
      "step: 659, loss: 0.00020767997193615884\n",
      "Checkpoint is saved\n",
      "step: 664, loss: 0.001368835335597396\n",
      "step: 669, loss: 0.4253212809562683\n",
      "step: 674, loss: 0.005994169041514397\n",
      "step: 679, loss: 0.03380550816655159\n",
      "Checkpoint is saved\n",
      "step: 684, loss: 0.004186644684523344\n",
      "step: 689, loss: 0.0028401906602084637\n",
      "step: 694, loss: 2.738988769124262e-05\n",
      "step: 699, loss: 0.00015657626499887556\n",
      "Checkpoint is saved\n",
      "step: 704, loss: 0.018793603405356407\n",
      "step: 709, loss: 0.0014855200424790382\n",
      "step: 714, loss: 3.215187825844623e-05\n",
      "step: 719, loss: 0.6588477492332458\n",
      "Checkpoint is saved\n",
      "step: 724, loss: 0.009104023687541485\n",
      "step: 729, loss: 6.347259477479383e-05\n",
      "step: 734, loss: 0.0002760244533419609\n",
      "step: 739, loss: 1.885657366074156e-05\n",
      "Checkpoint is saved\n",
      "step: 744, loss: 0.00012247715494595468\n",
      "step: 749, loss: 0.0002599279396235943\n",
      "step: 754, loss: 0.014362966641783714\n",
      "step: 759, loss: 0.09693972021341324\n",
      "Checkpoint is saved\n",
      "step: 764, loss: 0.07755637913942337\n",
      "step: 769, loss: 0.002427754458039999\n",
      "step: 774, loss: 0.0006445718463510275\n",
      "step: 779, loss: 9.83356439974159e-05\n",
      "Checkpoint is saved\n",
      "step: 784, loss: 1.0058458428829908e-05\n",
      "step: 789, loss: 0.0002854210906662047\n",
      "step: 794, loss: 0.09258914738893509\n",
      "step: 799, loss: 0.4445692300796509\n",
      "Checkpoint is saved\n",
      "step: 804, loss: 0.013376611284911633\n",
      "step: 809, loss: 0.12470462918281555\n",
      "step: 814, loss: 0.04262019693851471\n",
      "step: 819, loss: 0.059558119624853134\n",
      "Checkpoint is saved\n",
      "step: 824, loss: 0.0006033406243659556\n",
      "step: 829, loss: 0.011586329899728298\n",
      "step: 834, loss: 0.0002002524270210415\n",
      "step: 839, loss: 0.1338014304637909\n",
      "Checkpoint is saved\n",
      "step: 844, loss: 0.0914769321680069\n",
      "step: 849, loss: 0.03139043599367142\n",
      "step: 854, loss: 0.00037943554343655705\n",
      "step: 859, loss: 1.9772931409534067e-05\n",
      "Checkpoint is saved\n",
      "step: 864, loss: 0.012472530826926231\n",
      "step: 869, loss: 6.79490840411745e-05\n",
      "step: 874, loss: 6.573272912646644e-06\n",
      "step: 879, loss: 5.065533514425624e-06\n",
      "Checkpoint is saved\n",
      "step: 884, loss: 3.047750396945048e-06\n",
      "step: 889, loss: 2.5586575702618575e-06\n",
      "step: 894, loss: 3.7892707041464746e-05\n",
      "step: 899, loss: 0.5018439292907715\n",
      "Checkpoint is saved\n",
      "step: 904, loss: 0.10943353176116943\n",
      "step: 909, loss: 0.020187007263302803\n",
      "step: 914, loss: 2.8809221475967206e-05\n",
      "step: 919, loss: 2.5514391381875612e-05\n",
      "Checkpoint is saved\n",
      "step: 924, loss: 0.009230226278305054\n",
      "step: 929, loss: 0.0023762667551636696\n",
      "step: 934, loss: 0.2882479429244995\n",
      "step: 939, loss: 0.0820591002702713\n",
      "Checkpoint is saved\n",
      "step: 944, loss: 0.014898236840963364\n",
      "step: 949, loss: 0.0032466999255120754\n",
      "step: 954, loss: 0.10979662835597992\n",
      "step: 959, loss: 0.009226466529071331\n",
      "Checkpoint is saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 964, loss: 0.0012643396621569991\n",
      "step: 969, loss: 0.002305768197402358\n",
      "step: 974, loss: 0.006669139489531517\n",
      "step: 979, loss: 4.075112428836292e-06\n",
      "Checkpoint is saved\n",
      "step: 984, loss: 0.14210419356822968\n",
      "step: 989, loss: 0.09115472435951233\n",
      "step: 994, loss: 0.138443261384964\n",
      "step: 999, loss: 0.000737030990421772\n",
      "Checkpoint is saved\n",
      "Training time for 1000 steps: 1823.06853723526s\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "\n",
    "# we will use this list to plot losses through steps\n",
    "losses = []\n",
    "\n",
    "# save a checkpoint so we can restore the model later \n",
    "# del saver\n",
    "saver = tf.train.Saver()\n",
    "# restore = True\n",
    "\n",
    "print('------------------TRAINING------------------')\n",
    "with tf.Session() as sess:\n",
    "#     if (restore):\n",
    "#         saver.restore(sess, tf.train.latest_checkpoint('checkpointsSan/'))\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    t = time.time()\n",
    "    for step in range(steps):\n",
    "        feed = feed_dict(X_train, Y_train)\n",
    "            \n",
    "        backward_step(sess, feed)\n",
    "        \n",
    "        if step % 5 == 4 or step == 0:\n",
    "            loss_value = sess.run(loss, feed_dict = feed)\n",
    "            print('step: {}, loss: {}'.format(step, loss_value))\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        if step % 20 == 19:\n",
    "            saver.save(sess, 'checkpointsSan2Eng/', global_step=step)\n",
    "            print('Checkpoint is saved')\n",
    "            \n",
    "    print('Training time for {} steps: {}s'.format(steps, time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c61d588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(losses, linewidth = 1)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.ylim((-1, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpointsSan2Eng/-999\n",
      "1.\n",
      "--------------------------------\n",
      "इब्राहीमः सन्तानो दायूद् तस्य \n",
      "While they behold your chaste conversation coupled with fear  coupled now twelve  twelve While they behold your chaste conversation coupled with fear  coupled now twelve  twelve \n",
      "--------------------------------\n",
      "2.\n",
      "--------------------------------\n",
      "or if he ask a fish, will he give him a serpent?\n",
      "While they behold your chaste twelve  twelve  coupled of seed of seed of While they behold your chaste twelve  twelve  coupled of seed of seed of \n",
      "--------------------------------\n",
      "3.\n",
      "--------------------------------\n",
      "will he give him a serpent?\n",
      "While they behold your chaste conversation coupled with fear  spirits in fear  at While they behold your chaste conversation coupled with fear  spirits in fear  at \n",
      "--------------------------------\n",
      "4.\n",
      "--------------------------------\n",
      "I am reading a book\n",
      "While they behold your chaste conversation coupled at coupled with fear  fear  at While they behold your chaste conversation coupled at coupled with fear  fear  at \n",
      "--------------------------------\n",
      "5.\n",
      "--------------------------------\n",
      "सन्तानो यीशुख्रीष्टस्तस्य\n",
      "While they behold said  going fear  at coupled at coupled now twelve  twelve While they behold said  going fear  at coupled at coupled now twelve  twelve \n",
      "--------------------------------\n",
      "6.\n",
      "--------------------------------\n",
      "I am good\n",
      "While they behold your chaste conversation coupled with fear  coupled now twelve  twelve While they behold your chaste conversation coupled with fear  coupled now twelve  twelve \n",
      "--------------------------------\n",
      "7.\n",
      "--------------------------------\n",
      "Do you speak English\n",
      "While they behold your chaste conversation coupled with fear  coupled now twelve  twelve While they behold your chaste conversation coupled with fear  coupled now twelve  twelve \n",
      "--------------------------------\n",
      "8.\n",
      "--------------------------------\n",
      "What time is it\n",
      "Till can did  Are now things  happy whereof things Jesus of also  Till can did  Are now things  happy whereof things Jesus of also  \n",
      "--------------------------------\n",
      "9.\n",
      "--------------------------------\n",
      "Hi\n",
      "english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  \n",
      "--------------------------------\n",
      "10.\n",
      "--------------------------------\n",
      "Goodbye\n",
      "english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  \n",
      "--------------------------------\n",
      "11.\n",
      "--------------------------------\n",
      "Yes\n",
      "english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  \n",
      "--------------------------------\n",
      "12.\n",
      "--------------------------------\n",
      "No\n",
      "english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  english going chaste conversation coupled These going chaste conversation coupled with fear  twelve  \n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the model\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # placeholders\n",
    "    encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "    decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "    # output projection\n",
    "    size = 512\n",
    "    w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "    b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "    w = tf.transpose(w_t)\n",
    "    output_projection = (w, b)\n",
    "    \n",
    "    # change the model so that output at time t can be fed as input at time t+1\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                                encoder_inputs,\n",
    "                                                decoder_inputs,\n",
    "                                                tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                                num_encoder_symbols = en_vocab_size,\n",
    "                                                num_decoder_symbols = de_vocab_size,\n",
    "                                                embedding_size = 100,\n",
    "                                                feed_previous = True, # <-----this is changed----->\n",
    "                                                output_projection = output_projection,\n",
    "                                                dtype = tf.float32)\n",
    "    \n",
    "    # ops for projecting outputs\n",
    "    outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "    # let's translate these sentences     \n",
    "    en_sentences = [\"\\u0907\\u092c\\u094d\\u0930\\u093e\\u0939\\u0940\\u092e\\u0903 \\u0938\\u0928\\u094d\\u0924\\u093e\\u0928\\u094b \\u0926\\u093e\\u092f\\u0942\\u0926\\u094d \\u0924\\u0938\\u094d\\u092f \", \"or if he ask a fish, will he give him a serpent?\", \"will he give him a serpent?\", 'I am reading a book',\\\n",
    "                    '\\u0938\\u0928\\u094d\\u0924\\u093e\\u0928\\u094b \\u092f\\u0940\\u0936\\u0941\\u0916\\u094d\\u0930\\u0940\\u0937\\u094d\\u091f\\u0938\\u094d\\u0924\\u0938\\u094d\\u092f', 'I am good', 'Do you speak English', 'What time is it', 'Hi', 'Goodbye', 'Yes', 'No']\n",
    "    en_sentences_encoded = [[en_word2idx.get(word, 0) for word in en_sentence.split()] for en_sentence in en_sentences]\n",
    "    \n",
    "    # padding to fit encoder input\n",
    "    for i in range(len(en_sentences_encoded)):\n",
    "        en_sentences_encoded[i] += (15 - len(en_sentences_encoded[i])) * [en_word2idx['<pad>']]\n",
    "    \n",
    "    # restore all variables - use the last checkpoint saved\n",
    "    saver = tf.train.Saver()\n",
    "    path = tf.train.latest_checkpoint('checkpointsSan2Eng')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # restore\n",
    "        saver.restore(sess, path)\n",
    "        \n",
    "        # feed data into placeholders\n",
    "        feed = {}\n",
    "        for i in range(input_seq_len):\n",
    "            feed[encoder_inputs[i].name] = np.array([en_sentences_encoded[j][i] for j in range(len(en_sentences_encoded))], dtype = np.int32)\n",
    "            \n",
    "        feed[decoder_inputs[0].name] = np.array([de_word2idx['<go>']] * len(en_sentences_encoded), dtype = np.int32)\n",
    "        \n",
    "        # translate\n",
    "        output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "        \n",
    "        # decode seq.\n",
    "        for i in range(len(en_sentences_encoded)):\n",
    "            print('{}.\\n--------------------------------'.format(i+1))\n",
    "            ouput_seq = [output_sequences[j][i] for j in range(output_seq_len)]\n",
    "            #decode output sequence\n",
    "            words = decode_output(ouput_seq)\n",
    "        \n",
    "            print(en_sentences[i])\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    print((words[i]), end = \" \")\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    print(words[i], end = \" \")\n",
    "            \n",
    "            print('\\n--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model can be improved by using more training steps, better dataset or even with better selection of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
